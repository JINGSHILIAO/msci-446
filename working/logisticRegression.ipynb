{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n",
      "Done reading!\n",
      "Everything done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "import random\n",
    "import datetime\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import data\n",
    "seed = 44\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "print(\"Reading file...\")\n",
    "all_df = pd.read_csv('./data.csv', low_memory=False)\n",
    "print(\"Done reading!\")\n",
    "all_df['time'] = pd.to_datetime(all_df['timestamp'] * 1000000000)\n",
    "all_df = all_df.rename({'time': 'ds', 'percentOfMaxPrice': 'y'}, axis='columns')\n",
    "dfs = [v for k, v in all_df.groupby('itadPlain')]\n",
    "print(\"Everything done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, \\\n",
    "    TimeSeriesResampler\n",
    "\n",
    "onlyTrend = []\n",
    "for df in dfs:\n",
    "    onlyTrend.append(df['y'])\n",
    "\n",
    "trends = np.array(onlyTrend, dtype=object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Convert it so that it's compatible with numpy\n",
    "for i in range(0, len(trends)):\n",
    "    trends[i] = trends[i].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intro\n",
    "\n",
    "In this notebook, we are going to focus on the supervised learning models. Namely, linear regression of booleans, and the basic Markov Chain, and predicting based on trends (after classification).\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Standardize the length, then normalize around 0\n",
    "# X_train = TimeSeriesResampler(sz=80).fit_transform(trends)[:2000]\n",
    "# X_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\n",
    "X_train = trends\n",
    "np.random.shuffle(X_train)\n",
    "X_train = X_train[:2000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# Let's get started with the linear regression of booleans\n",
    "# In this case, we need to make our own records, except we have to pick them from different observations in the given data\n",
    "# We use a method, so that it's flexible, and we can compare its effectiveness if we do {classify and split before regression}, or {we don't.}\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def lin_reg_model_train(data,samples_per_game=10,num_prev_states=5,num_future_states=30,train_perc=0.8,model=GaussianNB(),verbose=False):\n",
    "    \"\"\"\n",
    "    Trains and returns a linear classifier.\n",
    "\n",
    "    :param model: Sklearn-compatible model to train\n",
    "    :param callback: Code to run at the end to evaluate performance.\n",
    "    :param train_perc: % of data dedicated to training\n",
    "    :param num_future_states: number of days to look in the future\n",
    "    :param num_prev_states: number of days to consider (in the past)\n",
    "    :param data: data to train on.\n",
    "    :param samples_per_game: Expected number of samples per game taken. (actual number may be higher or lower).\n",
    "    :return: trained model\n",
    "    \"\"\"\n",
    "    data_sz = len(data)\n",
    "    num_samples = data_sz * samples_per_game\n",
    "\n",
    "    observations = np.zeros((num_samples, num_prev_states + num_future_states), dtype=float)\n",
    "    selected_games = np.random.randint(data_sz, size=num_samples)\n",
    "    sample_len = num_prev_states + num_future_states\n",
    "    for ind, game_ind in enumerate(selected_games):\n",
    "        # Impossible to take a sample from a game that isn't long enough\n",
    "        if len(data[game_ind]) < sample_len:\n",
    "            # This creates an empty row. Make sure to filter it out later on.\n",
    "            continue\n",
    "        start_ind = random.randint(0, len(data[game_ind]) - sample_len)\n",
    "        observations[ind] = copy(data[game_ind][start_ind:start_ind + sample_len])\n",
    "\n",
    "\n",
    "    info = observations[~np.all(observations == 0, axis=1)]\n",
    "\n",
    "    # Label the data\n",
    "    X_raw, y_raw = info[:,:num_prev_states], info[:,num_prev_states:]\n",
    "\n",
    "\n",
    "    # Create arr that defaults to false\n",
    "    X =  np.full((len(info), 11), 0)\n",
    "    y = np.full((len(info), 11), False)\n",
    "\n",
    "    # Categorize into buckets of:\n",
    "    # [0, 0.1)\n",
    "    # [0.1, 0.2)\n",
    "    # etc.\n",
    "    # We set it to true if it's present\n",
    "    dividers = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1]\n",
    "\n",
    "    # Bin data to show if a given row contains a price in that bin.\n",
    "    for ind, row in enumerate(X_raw):\n",
    "        hist, _ = np.histogram(row, dividers)\n",
    "        for hist_ind in range(0, len(hist)):\n",
    "            X[ind, hist_ind] = hist[hist_ind]\n",
    "\n",
    "    # Do the same for the test data\n",
    "    for ind, row in enumerate(y_raw):\n",
    "        hist, _ = np.histogram(row, dividers)\n",
    "        for hist_ind in range(0, len(hist)):\n",
    "            if hist[hist_ind]:\n",
    "                y[ind, hist_ind] = True\n",
    "\n",
    "    X_train, X_test, y_train, y_test =train_test_split(X,y,test_size= 1-train_perc, random_state=0)\n",
    "\n",
    "    # importing standard scaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # scaling the input data\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.fit_transform(X_test)\n",
    "\n",
    "    # Train a model per prediction\n",
    "    accuracy_results = []\n",
    "    for i in range (0, 11):\n",
    "        target = y_train[:,i]\n",
    "        # training the model\n",
    "        model.fit(X_train, target)\n",
    "\n",
    "        # testing the model\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # import scikit-learn metrics module for accuracy calculation\n",
    "        from sklearn import metrics\n",
    "        # printing accuracy\n",
    "        accuracy =  metrics.accuracy_score(y_test[:,i], y_pred)\n",
    "        accuracy_results.append(accuracy)\n",
    "    if verbose:\n",
    "        print(f\"Accuracy: {np.round(accuracy_results, 2)}\")\n",
    "        print(f\"Mean: {np.round(np.mean(accuracy_results),4)}\\tStd: {np.round(np.std(accuracy_results),4)}\")\n",
    "\n",
    "    return model, accuracy_results\n",
    "\n",
    "_ = lin_reg_model_train(X_train, samples_per_game=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.92 0.66 0.66 0.82 0.69 0.92 0.91 0.81 0.84 0.92 0.12]\n",
      "Mean: 0.7507\tStd: 0.2221\n",
      "Accuracy: [0.96 0.69 0.77 0.88 0.86 0.92 0.92 0.8  0.85 0.97 0.98]\n",
      "Mean: 0.8717\tStd: 0.0864\n"
     ]
    },
    {
     "data": {
      "text/plain": "(GaussianNB(),\n [0.9564025651634257,\n  0.6907581712867191,\n  0.7654375258585022,\n  0.8810508895324782,\n  0.8633636739760033,\n  0.916037443111295,\n  0.921183285064129,\n  0.7962350020686801,\n  0.8538477451386016,\n  0.9687112122465866,\n  0.9760033098882913])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Gaussian Naive Bayes model\n",
    "\n",
    "\n",
    "# create a Gaussian Classifier\n",
    "gaus = GaussianNB()\n",
    "\n",
    "# Experiment\n",
    "# Seeing how more samples affect it\n",
    "# Hypothesis: Currently, with 1 sample per game, the accuracy hovers at around 70-80%. By 100x the samples per game up to 100, I expect the accuracy to similarly improve up to sqrt(0.7) to sqrt(0.75). Evauluated, the accuracy is ~0.83-0.86\n",
    "# Result: The 100 games performs roughly as well as the 1 sample per game, while also taking a fraction of the time to make. Do not use.\n",
    "lin_reg_model_train(X_train, samples_per_game=1, model=gaus, verbose=True)\n",
    "lin_reg_model_train(X_train, samples_per_game=100, model=gaus, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One accuracy mean: 0.8434172397785001, [0.83 0.85 0.82 0.86 0.86 0.87 0.86 0.84 0.77 0.87]\n",
      "Ten accuracy mean: 0.8715249365642341, [0.87 0.88 0.87 0.87 0.87 0.87 0.88 0.87 0.87 0.87]\n"
     ]
    }
   ],
   "source": [
    "# Experiment\n",
    "# Maybe that went too far? Let's try just doing 10x\n",
    "# Hypothesis: This will do nothing\n",
    "# Result: The 10 sample consistently outperforms the 1 sample by ~4%. Maybe there is a sweet spot somewhere in between 10-100? 10 sample also has way less variance.\n",
    "one_accuracy = []\n",
    "ten_accuracy = []\n",
    "for i in range(0, 10):\n",
    "    _, a = lin_reg_model_train(X_train, samples_per_game=1, model=gaus)\n",
    "    one_accuracy.append(np.mean(a))\n",
    "    _, b = lin_reg_model_train(X_train, samples_per_game=10, model=gaus)\n",
    "    ten_accuracy.append(np.mean(b))\n",
    "\n",
    "print(f\"One accuracy mean: {np.mean(one_accuracy)}, {np.round(one_accuracy, 2)}\")\n",
    "print(f\"Ten accuracy mean: {np.mean(ten_accuracy)}, {np.round(ten_accuracy, 2)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}